# app/tw_news.py ã€”v8R7-TWNEWSã€•
# å°è‚¡æ–°èï¼ˆä¸­æ–‡ï¼‰ï¼šæŠ“å– Google News RSSï¼ˆè¿‘ 24 å°æ™‚ï¼‰ï¼Œç„¡é‡‘é‘°
from __future__ import annotations
import requests, time, html
import xml.etree.ElementTree as ET
from datetime import datetime, timezone
from email.utils import parsedate_to_datetime

RSS_URL = "https://news.google.com/rss/search"

# é—œéµå­—å¯è‡ªè¡Œæ“´å……
TW_NEWS_QUERY = "å°è‚¡ OR åŠ æ¬ŠæŒ‡æ•¸ OR æ«ƒè²· OR å¤§ç›¤ OR å°ç©é›» OR é‡‘ç®¡æœƒ"

def _fetch_rss(q: str, when: str = "24h", hl: str = "zh-TW", gl: str = "TW") -> str:
    params = {
        "q": f"{q} when:{when}",
        "hl": hl,
        "gl": gl,
        "ceid": "TW:zh-Hant",
    }
    r = requests.get(RSS_URL, params=params, timeout=10)
    r.raise_for_status()
    return r.text

def _timeago(dt: datetime) -> str:
    now = datetime.now(timezone.utc)
    sec = int((now - dt).total_seconds())
    if sec < 60: return f"{sec} ç§’å‰"
    m = sec // 60
    if m < 60: return f"{m} åˆ†é˜å‰"
    h = m // 60
    if h < 48: return f"{h} å°æ™‚å‰"
    d = h // 24
    return f"{d} å¤©å‰"

def _parse_items(xml_text: str, limit: int = 10):
    root = ET.fromstring(xml_text)
    ch = root.find("channel")
    if ch is None: return []
    out = []
    for it in ch.findall("item"):
        title = (it.findtext("title") or "").strip()
        link = (it.findtext("link") or "").strip()
        pub = it.findtext("{http://www.w3.org/2005/Atom}updated") or it.findtext("pubDate") or ""
        try:
            dt = parsedate_to_datetime(pub) if pub else None
            if dt and not dt.tzinfo:
                dt = dt.replace(tzinfo=timezone.utc)
        except Exception:
            dt = None
        out.append({
            "title": html.unescape(title),
            "link": link,
            "dt": dt,
            "timeago": _timeago(dt) if dt else "",
        })
    # å»é‡ã€å–å‰ N
    seen = set(); uniq = []
    for x in out:
        k = x["title"]
        if k and k not in seen:
            seen.add(k); uniq.append(x)
    return uniq[:limit]

def recent_tw_news(k: int = 6) -> list[dict]:
    try:
        xml_text = _fetch_rss(TW_NEWS_QUERY, when="24h")
        return _parse_items(xml_text, limit=k)
    except Exception:
        return []

def format_tw_news_block(k: int = 3) -> str:
    items = recent_tw_news(k=k)
    if not items:
        return "ğŸ—ï¸ å°è‚¡æ–°èï¼ˆè¿‘ 24hï¼‰ï¼šæš«ç„¡å¯ç”¨é …ç›®æˆ–å–å¾—å¤±æ•—ã€‚"
    lines = ["ğŸ—ï¸ å°è‚¡æ–°èï¼ˆè¿‘ 24hï¼‰"]
    for i, it in enumerate(items, 1):
        lines.append(f"{i}. {it['title']} ã€”{it['timeago']}ã€•")
    return "\n".join(lines)
